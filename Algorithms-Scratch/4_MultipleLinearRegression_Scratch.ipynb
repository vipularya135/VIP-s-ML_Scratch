{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) From Scratch"
      ],
      "metadata": {
        "id": "WL9wbKwJCO-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self, X, Y):\n",
        "        ones = np.ones((X.shape[0], 1))\n",
        "        X = np.append(ones, X, axis=1)\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.m = X.shape[0]\n",
        "        self.n = X.shape[1]\n",
        "        self.theta = np.random.randn(X.shape[1])\n",
        "\n",
        "    def computeCostFunction(self):\n",
        "        h = np.matmul(self.X, self.theta)\n",
        "        self.J = (1 / (2 * self.m)) * np.sum((h - self.Y) ** 2)\n",
        "        return self.J\n",
        "\n",
        "    def performGradientDescent(self, num_of_iter, alpha):\n",
        "        self.Cost_history = []\n",
        "        self.theta_history = []\n",
        "        for x in range(num_of_iter):\n",
        "            h = np.matmul(self.X, self.theta)\n",
        "            J = self.computeCostFunction()\n",
        "            self.Cost_history.append(J)\n",
        "            self.theta_history.append(self.theta)\n",
        "            temp = h - self.Y\n",
        "            self.theta = self.theta - (alpha / self.m) * (self.X.T.dot(temp))\n",
        "        return self.theta, self.Cost_history, self.theta_history\n",
        "\n",
        "    def predict(self, X_test, Y_test):\n",
        "        ones = np.ones((X_test.shape[0], 1))\n",
        "        X_test = np.append(ones, X_test, axis=1)\n",
        "        self.Y_pred = np.matmul(X_test, self.theta)\n",
        "        self.error_percentage = (abs(self.Y_pred - Y_test) / Y_test) * 100\n",
        "        return self.Y_pred, self.error_percentage\n",
        "\n",
        "    def predictUsingNormalEquation(self, X_test, Y_test):\n",
        "        ones = np.ones((X_test.shape[0], 1))\n",
        "        X_test = np.append(ones, X_test, axis=1)\n",
        "        inv = np.linalg.inv(np.matmul(self.X.T, self.X))\n",
        "        self.w = np.matmul(np.matmul(inv, self.X.T), self.Y)\n",
        "        y_pred = np.matmul(X_test, self.w)\n",
        "        return y_pred, (abs(Y_test - y_pred) / Y_test) * 100\n",
        "\n",
        "# Load the diabetes dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/machine_learning/datasets/diabetes.csv')\n",
        "\n",
        "# Extract features (X) and target variable (Y)\n",
        "X = data.iloc[:, :-1].values\n",
        "Y = data.iloc[:, -1].values\n",
        "\n",
        "# Create a LinearRegression object\n",
        "model = LinearRegression(X, Y)\n",
        "\n",
        "# Perform gradient descent\n",
        "num_of_iter = 1000\n",
        "alpha = 0.01\n",
        "theta_final, cost_history, theta_history = model.performGradientDescent(num_of_iter, alpha)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "split_index = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "Y_train, Y_test = Y[:split_index], Y[split_index:]\n",
        "\n",
        "# Use the trained model to predict on the test set\n",
        "Y_pred, error_percentage = model.predict(X_test, Y_test)\n",
        "\n",
        "print(\"True Values:\", Y_test)\n",
        "print(\"Predicted Values:\", Y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXxZlE27BVhw",
        "outputId": "1b82929b-1d8f-41ba-ae47-c414af403240"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Values: [1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0\n",
            " 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 1 0]\n",
            "Predicted Values: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-78b87de364f4>:18: RuntimeWarning: overflow encountered in square\n",
            "  self.J = (1 / (2 * self.m)) * np.sum((h - self.Y) ** 2)\n",
            "<ipython-input-5-78b87de364f4>:25: RuntimeWarning: invalid value encountered in matmul\n",
            "  h = np.matmul(self.X, self.theta)\n",
            "<ipython-input-5-78b87de364f4>:17: RuntimeWarning: invalid value encountered in matmul\n",
            "  h = np.matmul(self.X, self.theta)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Using SCIKIT"
      ],
      "metadata": {
        "id": "fpSQHbd3CTlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/machine_learning/datasets/diabetes.csv')\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "Y = data.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"True Values:\", Y_test)\n",
        "print(\"Predicted Values:\", Y_pred)\n",
        "\n",
        "r2_accuracy = r2_score(Y_test, Y_pred)\n",
        "print(\"Accuracy:\", r2_accuracy)\n"
      ],
      "metadata": {
        "id": "AvgWYu3DUAu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f71ba6-93f1-4a87-8f4e-d121c5f75afd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Values: [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0\n",
            " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0]\n",
            "Predicted Values: [ 0.33550028  0.23809869  0.1510522   0.2401365   0.48142376  0.45257375\n",
            " -0.17450469  0.60662287  0.52417796  0.70476953  0.32360466  0.85290601\n",
            "  0.38466612  0.36056948  0.09946712  0.41539557  0.17869123  0.07782301\n",
            "  0.80730861  0.51299477  0.28090594  0.08303057  0.5099157   0.11381771\n",
            "  0.51325022  0.82528549  0.17892718 -0.0594202   0.28338572  0.16407949\n",
            "  0.83851225  0.80737515  0.68154389  0.7649502   0.56140297  0.62123131\n",
            "  1.06134554  0.30990775  0.51752336  0.63691482  0.07075333  0.57757007\n",
            "  0.55015462  0.37541745 -0.07644182  0.50119208  0.59600162  0.27464761\n",
            "  0.42477995  0.9941898   0.00969584  0.61763578  0.73395288  0.31090975\n",
            "  0.13456812 -0.02536316  0.71219147 -0.30518218  0.41994556  0.67869594\n",
            "  0.66891428  0.3798452   0.2956646   0.288035    0.06813053  0.55464338\n",
            "  0.01368504  0.6272007  -0.02033281  0.6372293   0.61928494  0.07019372\n",
            "  0.26388322  0.14080565  0.12425109  0.50054317  0.24772661  0.21027229\n",
            "  0.18419241  0.28346361  0.60206367  0.19720081  0.04718638  0.39163459\n",
            "  0.31373787  0.75789609  0.82549769  0.35944228  0.1723114   0.0957888\n",
            "  0.05894136  0.277268   -0.35746245  0.52802473  0.48569971  0.57670079\n",
            "  0.40681613  0.16649133  0.56927171  0.09451543  0.6570335   0.03311435\n",
            "  0.68073803  0.48441106  0.58967882  0.27055501  0.33149868  0.66512401\n",
            "  0.17581258  0.51566149  0.13045166  0.38010107 -0.0949753   0.65582849\n",
            "  0.23302651  0.3716743   0.68391471  0.28174341  0.05450268  0.53690397\n",
            "  0.04284507  0.33357357  0.30472023  0.10053203  0.33006507  0.44782371\n",
            "  0.02663058  0.82020965  1.03616317  0.66672645  0.6518381   0.77042295\n",
            "  0.11555357  0.44926623  0.72795331  0.15230489  0.21288603  0.76637265\n",
            "  0.72722441 -0.20395979  0.12946513 -0.02149655  0.27508285  0.39903148\n",
            "  0.15993455  0.33468331  0.20438069 -0.12662191  0.43170733  0.68158975\n",
            "  0.163167    0.4815615   0.30101739  0.26110909]\n",
            "Accuracy: 0.2550028117674177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPqWWWkBUAxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6L8y9Uu9UA0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amK9Q4fkUA3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_TpnucLUA6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}